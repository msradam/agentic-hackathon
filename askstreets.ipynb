{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AskStreets: Query and Visualizing Street Networks using OpenStreetMap, ArangoDB, and LangGraph\n",
    "Author: Adam Munawar Rahman, March 2025\n",
    "\n",
    "Using powerful libraries like OSMnx, we can retrieve street networks and feature datasets from OpenStreetMap and persist them as graph and collections in ArangoDB. Then, with a  ReACT agent model, feed natural language queries to LLMs to execute complex lookups, run GPU backed graph algorithms, and visualize geospatial coordinates - all to enable streamlined insights into the network properties of the geographic area we are analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import traceback\n",
    "import yaml\n",
    "\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import nx_arangodb as nxadb\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "\n",
    "from arango import ArangoClient\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderUnavailable\n",
    "from geopy.geocoders import Nominatim\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
    "from langchain_community.graphs import ArangoGraph\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_ibm import ChatWatsonx\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Loading OpenStreetMap Networks and Features to ArangoDB\n",
    "We can retrieve both street networks (consisting of nodes and edges representing the different types of paths that can be traversed between the geographic locations) and features (consisting of points associated with specific attributes like amenity type) by calling `ox.graph_from_address` and `ox.features_from_address`. \n",
    "\n",
    "In this instance, I'm using my workplace in NYC - IBM at One Madison  Avenue - to build our datasets from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the street network from OpenStreetMap using the built-in OSMnx function\n",
    "G_ox = ox.graph_from_address(\"1 Madison Ave, Manhattan, NY\", dist=250.0)\n",
    "\n",
    "# # Drop the shapely.Linestring attribute as it is not serializable to JSON, preventing ArangoDB persistence\n",
    "for node1, node2, edge_dict in G_ox.edges(data=True):\n",
    "    edge_dict.pop('geometry', None)\n",
    "    \n",
    "print(f\"Graph of street network within a 250 meter radius of One Madison Avenue: {G_ox}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox.plot_graph(G_ox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the nodes in the OSMnx graph do not include the address, we reverse geocode each node\n",
    "geolocator = Nominatim(user_agent=\"osmnx_geocoder\")\n",
    "for node_id, node_data in G_ox.nodes(data=True):\n",
    "    lat = node_data['y']\n",
    "    lon = node_data['x']\n",
    "    \n",
    "    try:\n",
    "        # Use reverse geocoding on points to get address information\n",
    "        location = geolocator.reverse(f\"{lat}, {lon}\", exactly_one=True, timeout=None)\n",
    "        if location:\n",
    "            # Add address information to the node\n",
    "            G_ox.nodes[node_id]['address'] = location.address\n",
    "\n",
    "        # Avoid possible rate limiting by waiting a bit between each node\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding node {node_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The node identifiers change when persisting the graph to ArangoDB, so to allow the tools to better communicate with each other,\n",
    "# e.g. when passing OSMnx results to the AQL tool, let's include current NetworkX node IDs so ArangoDB can access them\n",
    "for node_id, node_data in G_ox.nodes(data=True):\n",
    "    G_ox.nodes[node_id]['ID'] = node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "madison_filepath = \"./data/madison.graphml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save street network graph \n",
    "ox.io.save_graphml(G_ox, madison_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load street network graph from saved file\n",
    "G_ox = ox.io.load_graphml(madison_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list_with_addresses = list(G_ox.nodes(data=True))\n",
    "print(f\"Sample node data with address: {node_list_with_addresses[0]}\")\n",
    "print(f\"Sample node data with address: {node_list_with_addresses[65]}\")\n",
    "print(f\"Sample node data with address: {node_list_with_addresses[120]}\")\n",
    "print(f\"Sample node data with address: {node_list_with_addresses[34]}\")\n",
    "\n",
    "edge_list = list(G_ox.edges(data=True))\n",
    "print(f\"Sample edge data: {edge_list [0]}\")\n",
    "print(f\"Sample edge data: {edge_list [65]}\")\n",
    "print(f\"Sample edge data: {edge_list [120]}\")\n",
    "print(f\"Sample edge data: {edge_list [34]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve OpenStreet map features within the area of the street network that we just received\n",
    "# Refer to https://wiki.openstreetmap.org/wiki/Map_features for the specific features\n",
    "\n",
    "# Collecting a large number of tags improves the diversity of queries we can make!\n",
    "tags = {'building': True, 'amenity': True, 'healthcare': True, 'office': True, 'public_transport': True, 'craft': True, 'historic': True}\n",
    "features_gdf = ox.features.features_from_address(\"1 Madison Ave, Manhattan, NY\", tags, 250.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to avoid warnings given by geopandas regarding the centroid accuracy\n",
    "# Some of the geometries in the GeoDataFrame returned by OSMnx are polygons \n",
    "# that give a bounding box for a particular feature\n",
    "\n",
    "# To simplify the process so that each feature has an associated lat and long,\n",
    "# we just return the centroid of the geometry instead\n",
    "# e.g. for a bounding box, just return the center point \n",
    "# this will be sufficient for performing calculations on said feature\n",
    "utm_crs = ox.projection.project_gdf(features_gdf).crs\n",
    "features_gdf['lat'] = features_gdf.to_crs(utm_crs).centroid.to_crs(features_gdf.crs).y\n",
    "features_gdf['lon'] = features_gdf.to_crs(utm_crs).centroid.to_crs(features_gdf.crs).x\n",
    "\n",
    "features_gdf_adjusted = features_gdf.drop(columns=['geometry','type'])\n",
    "\n",
    "features_json_str = features_gdf_adjusted.reset_index().to_json(orient='records')\n",
    "features_records = json.loads(features_json_str)\n",
    "\n",
    "# OSMnx still pulls in many tag labels that resolve to None, let's remove them\n",
    "for feature in features_records:\n",
    "    for key, value in list(feature.items()):\n",
    "        if value is None:\n",
    "            del feature[key]\n",
    "\n",
    "print(f\"Sample feature data (Courthouse): {features_records[1]}\\n\")\n",
    "print(f\"Sample feature data (Citi Bike Rental): {features_records[43]}\\n\")\n",
    "print(f\"Sample feature data (Subway Platform): {features_records[418]}\\n\")\n",
    "print(f\"Sample feature data (Beam Charging Station): {features_records[97]}\\n\")\n",
    "print(f\"Sample feature data (School): {features_records[221]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our graph network and features dictionary are now prepared to load into ArangoDB, let's connect to the ArangoDB instance and create the database to store our One Madison data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in credentials file to dictionary, includes API keys and ArangoDB info\n",
    "credentials = yaml.load(open('credentials.yml'), Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArangoDB credentials\n",
    "adb_host = credentials[\"DATABASE_HOST\"]\n",
    "adb_user = credentials[\"DATABASE_USERNAME\"]\n",
    "adb_pass = credentials[\"DATABASE_PASSWORD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the running ArangoDB instance - in my case, the Community Edition Docker container\n",
    "client = ArangoClient(hosts=adb_host)\n",
    "# Connect to the \"_system\" database\n",
    "sys_db = client.db('_system',username=adb_user,password=adb_pass,verify=True)\n",
    "\n",
    "# Create the database to store graph and features collection for One Madison Avenue\n",
    "if not sys_db.has_database('madison'):\n",
    "    sys_db.create_database('madison')\n",
    "\n",
    "madison_db = client.db('madison',username=adb_user,password=adb_pass,verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OSM graph is a MultiDiGraph - i.e. a Directed Graph that contains nodes that can have multiple edges between them\n",
    "# Let's make sure we persist it in ArangoDB as the same type\n",
    "G_ox_adb = nxadb.MultiDiGraph(\n",
    "    name=\"G_ox_adb\",\n",
    "    db=madison_db,\n",
    "    incoming_graph_data=G_ox,\n",
    "    overwrite_graph=True\n",
    ")\n",
    "print(f\"Graph of One Madison Ave street network persisted to ArangoDB: {G_ox_adb}\")\n",
    "\n",
    "# Jupyter Notebook occasionally misreports the graph has having 0 edges when loaded into ArangoDB\n",
    "# Verify that the correct number of nodes and edges are there\n",
    "print(f\"True number of nodes in G_ox_adb is: {G_ox_adb.number_of_nodes()}\")\n",
    "print(f\"True number of edges in G_ox_adb is: {G_ox_adb.number_of_edges()}\")\n",
    "\n",
    "# Sometimes the true number of edges is also reported as 0, so I re-run the cell to reimport the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the features JSON to ArangoDB as a collection so it is accessible via AQL\n",
    "if madison_db.has_collection('features'):\n",
    "    madison_db.delete_collection('features')\n",
    "features_collection = madison_db.create_collection('features')\n",
    "\n",
    "features_collection.insert_many(features_records)\n",
    "print(f\"Added {len(features_records)} feature records to ArangoDB 'features' collection in the Madison database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ArangoGraph LangChain wrapper for the One Madison Avenue database\n",
    "arango_graph = ArangoGraph(madison_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Defining the LLM-based tools for the ReACT Agent App\n",
    "In this portion of the code we define four AI tools:\n",
    "1. `text_to_aql_to_text` - Generates ArangoDB Query Language based on the natural language query\n",
    "2. `text_to_osmnx_algorithm_to_text` - Generates OSMnx/NetworkX Python code based on the natural language query\n",
    "3. `text_to_geocoder_to_coordinates` - Extracts the geographic location from the natural language query and geocodes it\n",
    "4. `text_to_coordinates_to_folium_map` - Extracts geospatial coordinates from the query and plots them on a Folium map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the LLM provider\n",
    "# Choice of 'OPENAI', 'ANTHROPIC', and 'WATSONX'\n",
    "AI_PLATFORM = \"OPENAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if AI_PLATFORM == \"ANTHROPIC\":\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = credentials[\"ANTHROPIC_API_KEY\"]\n",
    "elif AI_PLATFORM == \"OPENAI\":\n",
    "    os.environ[\"OPENAI_API_KEY\"] = credentials[\"OPENAI_API_KEY\"]\n",
    "elif AI_PLATFORM == \"WATSONX\":\n",
    "    os.environ[\"WATSONX_API_KEY\"] = credentials[\"WATSONX_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def text_to_aql_to_text(query):\n",
    "    \"\"\"\n",
    "    Translates natural language to AQL, executes against Arango database, returns results as text.\n",
    "\n",
    "    USE THIS TOOL WHEN:\n",
    "    - Querying the graph in ArangoDB (nodes, edges, features collections)\n",
    "    - Finding relationships/paths between locations or buildings\n",
    "    - Performing aggregations, filters, or sorting on stored data\n",
    "    - Looking up properties like names, addresses, or building types\n",
    "    - Counting or listing street network elements with specific attributes\n",
    "\n",
    "    DO NOT USE WHEN:\n",
    "    - Working with the in-memory OSMnx graph object\n",
    "    - Calculating network metrics like centrality or clustering\n",
    "    - Performing advanced spatial operations\n",
    "    \"\"\"\n",
    "    print(f\"üîç AQL Tool: Starting to process query: '{query}'\")\n",
    "\n",
    "    if AI_PLATFORM == \"ANTHROPIC\":\n",
    "        llm = ChatAnthropic(temperature=0, model_name=\"claude-3-7-sonnet-20250219\")\n",
    "    elif AI_PLATFORM == \"OPENAI\":\n",
    "        llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "    elif AI_PLATFORM == \"WATSONX\":\n",
    "        llm = ChatWatsonx(temperature=0, model_name=\"ibm/granite-34b-code-instruct\")\n",
    "\n",
    "    print(f\"üîç AQL Tool: Initialized LLM\")\n",
    "\n",
    "    # Enhance the query by adding context to the original question posed by the user\n",
    "    # referencing the attributes of the graphs and collections store in ArangoDB\n",
    "\n",
    "    schema_context = \"\"\"\n",
    "    You are an experienced graph network analyst proficient in writing ArangoDB Query Language.\n",
    "\n",
    "    This query is about data including but not limited to these collections:\n",
    "\n",
    "    1. G_ox_adb_node: Street intersections with attributes:\n",
    "    - x, y: Coordinates (longitude, latitude)\n",
    "    - osmid: OpenStreetMap ID\n",
    "    - highway: Type of intersection (junction, traffic_signals, etc.)\n",
    "    - address: Real world location of the node\n",
    "    - ID: The original ID from the NetworkX version of the graph\n",
    "\n",
    "    2. G_ox_adb_edge: Street segments connecting intersections\n",
    "    - length: length in meters\n",
    "    - name: Street name\n",
    "    - oneway: Boolean indicating if it's a one-way street\n",
    "\n",
    "    3. features: Features of the area with attributes:\n",
    "    - osmid: OpenStreetMap ID\n",
    "    - element_type: 'node' or 'way'\n",
    "    - the following OpenStreetMap feature tags\n",
    "        - building: Boolean yes/no indicating if the feature is a building\n",
    "        - amenity: The type of amenity the feature is e.g. cafe, bank\n",
    "        - healthcare: The health specialty e.g. nurse, optometrist\n",
    "        - office: The type of company the office is for e.g. financial, airline\n",
    "        - public_transport: The type of public transport feature e.g. platform, station\n",
    "        - craft: Describes the type of craft the feature is for e.g. bakery, jeweller\n",
    "        - historic: Describes the type of historic site, e.g. house, memorial\n",
    "    - name: Name of the feature\n",
    "    - lat, lon: geospatial coordinates of the feature\n",
    "\n",
    "    # TASK\n",
    "    Generate executable AQL to answer this query. \n",
    "    \n",
    "    If the query asks for a path to the nearest feature, first find a node on the graph that is closest to that feature, \n",
    "    then run the algorithm.\n",
    "\n",
    "    If the query specifies node IDs, use the ID attribute of the node. \n",
    "    For example, if the query asks \"Find the address of the intersection with node ID 247798296.\", then use node.ID instead of node._key.\n",
    "\n",
    "    If the query specifies a generic location type like 'cafe', 'office', 'subway' or 'bank', use the amenity attribute. \n",
    "    Use the other OpenStreetMap feature tags if the query is more specific.\n",
    "\n",
    "    For example, if there is a building located at a certain latitude and longitude, and the query asks for a path to get to that building,\n",
    "    first find a node in the graph that has the nearest straight line distance to that building, then use that node for the traversal algorithm.\n",
    "\n",
    "    Focus on writing efficient AQL queries that:\n",
    "    1. Use FILTER, SORT, LIMIT as needed to optimize performance\n",
    "    2. Use graph traversals for finding paths and connections\n",
    "    3. Return well-structured data that directly answers the question\n",
    "    4. Include relevant coordinates and attributes in the results\n",
    "    \"\"\"\n",
    "    context = schema_context\n",
    "    enhanced_query = f\"{context} Query: {query}\"\n",
    "\n",
    "    try:\n",
    "        chain = ArangoGraphQAChain.from_llm(\n",
    "            llm=llm, graph=arango_graph, verbose=True, allow_dangerous_requests=True\n",
    "        )\n",
    "\n",
    "        print(\"üîç AQL Tool: Executing query against ArangoDB\")\n",
    "        result = chain.invoke(enhanced_query)\n",
    "        return str(result[\"result\"])\n",
    "        print(\"üîç AQL Tool: Completed AQL query ‚úÖ\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üîç AQL Tool: ERROR executing query: {str(e)} ‚ùå\")\n",
    "        return f\"Error executing the database query: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def text_to_osmnx_algorithm_to_text(query):\n",
    "    \"\"\"\n",
    "    Executes OSMnx/NetworkX algorithms on the in-memory street network graph.\n",
    "\n",
    "    USE THIS TOOL WHEN:\n",
    "    - Calculating network metrics (centrality, connectivity, clustering)\n",
    "    - Finding paths using specialized algorithms\n",
    "    - Analyzing network topology and structure\n",
    "    - Performing spatial operations (nearest nodes, isochrones)\n",
    "    - Computing network statistics or identifying critical components\n",
    "\n",
    "    DO NOT USE WHEN:\n",
    "    - Querying existing database records\n",
    "    - Looking up specific street or building properties\n",
    "    - Creating visualizations\n",
    "    - Geocoding addresses\n",
    "    \"\"\"\n",
    "    print(f\"üöè OSMnx Tool: Starting to process query: '{query}'\")\n",
    "\n",
    "    if AI_PLATFORM == \"ANTHROPIC\":\n",
    "        llm = ChatAnthropic(temperature=0, model_name=\"claude-3-7-sonnet-20250219\")\n",
    "    elif AI_PLATFORM == \"OPENAI\":\n",
    "        llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "    elif AI_PLATFORM == \"WATSONX\":\n",
    "        llm = ChatWatsonx(temperature=0, model_name=\"ibm/granite-34b-code-instruct\")\n",
    "\n",
    "    print(\"üöè OSMnx Tool: Initialized LLM\")\n",
    "\n",
    "    # Step 1: Generate OSMnx code\n",
    "    print(\"üöè OSMnx Tool: 1) Generating OSMnx code\")\n",
    "\n",
    "    code_generation_prompt = f\"\"\"\n",
    "    You are an expert in network analysis using OSMnx and NetworkX. \n",
    "    I need you to translate a natural language query into precise Python code.\n",
    "    \n",
    "    # GRAPH SCHEMA\n",
    "    I have an OSMnx Graph called `G_ox` with the following schema: {arango_graph.schema}\n",
    "    \n",
    "    # QUERY TO ANALYZE\n",
    "    Natural language query: {query}\n",
    "    \n",
    "    # TASK\n",
    "    Generate executable Python code to answer this query using NetworkX/OSMnx algorithms.\n",
    "    \n",
    "    # GRAPH DETAILS\n",
    "    The `G_ox` graph is an in-memory OSMnx graph representing a street network with these characteristics:\n",
    "    - Each node represents an intersection with geospatial coordinates\n",
    "    - Each edge represents a street segment connecting intersections\n",
    "    - Nodes have attributes like 'x' and 'y' coordinates, 'osmid', and sometimes 'address'\n",
    "    - Edges have attributes like 'length', 'name', 'highway' type, and sometimes 'oneway'\n",
    "    \n",
    "    # ALGORITHM SELECTION GUIDELINES\n",
    "    - For centrality: Use nx.betweenness_centrality(), nx.closeness_centrality(), or nx.degree_centrality()\n",
    "    - For connectivity: Use nx.node_connectivity(), nx.edge_connectivity(), or nx.is_strongly_connected()\n",
    "    - For clustering: Use nx.clustering(), or community detection algorithms\n",
    "    - For shortest paths: Use nx.shortest_path(), nx.shortest_path_length(), or ox.distance.shortest_path()\n",
    "    - For accessibility: Compute isochrones or service areas using nx.ego_graph() or custom functions\n",
    "    - For statistics: Use ox.stats.basic_stats() or custom calculations\n",
    "    \n",
    "    # CODE STRUCTURE\n",
    "    - Include descriptive variable names and brief comments\n",
    "    - For node lookups by coordinates: Use `node_id = ox.distance.nearest_nodes(G_ox, lon, lat)`\n",
    "    - For path finding between points: First find nearest nodes, then compute shortest path\n",
    "    - Focus on the specific algorithm needed rather than general exploration\n",
    "    - Set the final answer as `FINAL_RESULT` - this should be a CONCISE representation of the answer\n",
    "    - For visualization queries or path analyses, include relevant coordinates in the result\n",
    "    - Format results for human readability (round numbers, provide units, use descriptive labels)\n",
    "    \n",
    "    Only provide Python code that can be executed via `exec()`. No explanations or markdown.\n",
    "    \"\"\"\n",
    "\n",
    "    text_to_osmnx = llm.invoke(code_generation_prompt).content\n",
    "    text_to_osmnx_cleaned = re.sub(\n",
    "        r\"^```python\\n|```$\", \"\", text_to_osmnx, flags=re.MULTILINE\n",
    "    ).strip()\n",
    "\n",
    "    print(\"üöè OSMnx Tool: Generated code:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(text_to_osmnx_cleaned)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Step 2: Execute OSMnx code\n",
    "    print(\"\\nüöè OSMnx Tool: 2) Executing OSMnx code\")\n",
    "    global_vars = {\"G_ox\": G_ox, \"ox\": ox, \"nx\": nx, \"pd\": pd, \"np\": np}\n",
    "    local_vars = {}\n",
    "\n",
    "    try:\n",
    "        exec(text_to_osmnx_cleaned, global_vars, local_vars)\n",
    "        print(\"üöè OSMnx Tool: Code executed successfully! ‚úÖ\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üöè OSMnx Tool: EXEC ERROR: {str(e)} ‚ùå\")\n",
    "\n",
    "        # Code correction mechanism\n",
    "        MAX_ATTEMPTS = 3\n",
    "        for attempt in range(1, MAX_ATTEMPTS + 1):\n",
    "            print(\n",
    "                f\"üöè OSMnx Tool: Attempting code correction: Attempt {attempt}/{MAX_ATTEMPTS}\"\n",
    "            )\n",
    "\n",
    "            correction_prompt = f\"\"\"\n",
    "            The following OSMnx/NetworkX code failed with error: {str(e)}\n",
    "            \n",
    "            Original code:\n",
    "            ```python\n",
    "            {text_to_osmnx_cleaned}\n",
    "            ```\n",
    "            \n",
    "            Fix the code to properly execute and answer the query: \"{query}\"\n",
    "            \n",
    "            Common issues to check:\n",
    "            1. Node or edge access methods (G_ox.nodes vs G_ox.nodes() or attribute access)\n",
    "            2. Parameter types or values (ensure coordinates are float, IDs are correct types)\n",
    "            3. Missing error handling (add try/except for node lookups, path finding)\n",
    "            4. Incorrect attribute names (verify the attributes actually exist in the graph)\n",
    "            5. Algorithm parameter requirements (some functions need specific inputs)\n",
    "            \n",
    "            Provide only the corrected code, no explanations.\n",
    "            \"\"\"\n",
    "\n",
    "            corrected_code = llm.invoke(correction_prompt).content\n",
    "            corrected_code_cleaned = re.sub(\n",
    "                r\"^```python\\n|```$\", \"\", corrected_code, flags=re.MULTILINE\n",
    "            ).strip()\n",
    "\n",
    "            print(f\"üöè OSMnx Tool: Corrected code (attempt {attempt}):\")\n",
    "            print(\"-\" * 50)\n",
    "            print(corrected_code_cleaned)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            try:\n",
    "                exec(corrected_code_cleaned, global_vars, local_vars)\n",
    "                text_to_osmnx_final = corrected_code_cleaned\n",
    "                print(f\"üöè OSMnx Tool: Correction successful on attempt {attempt} ‚úÖ\")\n",
    "                break\n",
    "            except Exception as e2:\n",
    "                print(f\"üöè OSMnx Tool: Correction attempt {attempt} failed: {str(e2)} ‚ùå\")\n",
    "\n",
    "                if attempt == MAX_ATTEMPTS:\n",
    "                    error_msg = f\"Unable to execute the OSMnx algorithm after {MAX_ATTEMPTS} attempts. Last error: {str(e2)}\"\n",
    "                    print(f\"üöè OSMnx Tool: {error_msg} ‚ùå\")\n",
    "                    return error_msg\n",
    "\n",
    "    if \"FINAL_RESULT\" not in local_vars:\n",
    "        error_msg = (\n",
    "            \"Error: The code executed but did not set the FINAL_RESULT variable.\"\n",
    "        )\n",
    "        print(f\"üöè OSMnx Tool: {error_msg} ‚ùå\")\n",
    "        return error_msg\n",
    "\n",
    "    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n",
    "    print(\"üöè OSMnx Tool: Execution completed with result:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"FINAL_RESULT: {FINAL_RESULT}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Step 3: Formulate final answer\n",
    "    print(\"üöè OSMnx Tool: 3) Formulating final answer\")\n",
    "\n",
    "    natural_language_prompt = f\"\"\"\n",
    "        # QUERY AND RESULTS\n",
    "        Original query: \"{query}\"\n",
    "        \n",
    "        Analysis result: {FINAL_RESULT}\n",
    "        \n",
    "        # TASK\n",
    "        Provide a clear, concise response that directly answers the original query based on the analysis result.\n",
    "        \n",
    "        Guidelines:\n",
    "        - Explain what the result means in plain language\n",
    "        - If the result is numeric, provide context for interpreting it\n",
    "        - If the result identifies specific locations/streets, name them explicitly\n",
    "        - For network metrics, explain their significance briefly (e.g., \"high betweenness centrality means...\")\n",
    "        - If the result contains coordinates, format them clearly for potential visualization\n",
    "        - Do not mention the code or algorithms used unless specifically asked\n",
    "        \n",
    "        Your response:\n",
    "    \"\"\"\n",
    "\n",
    "    osmnx_to_text = llm.invoke(natural_language_prompt).content\n",
    "    print(\"üöè OSMnx Tool: Final answer:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(osmnx_to_text)\n",
    "    print(\"-\" * 50)\n",
    "    print(\"üöè OSMnx Tool: Processing complete ‚úÖ\")\n",
    "\n",
    "    return osmnx_to_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def text_to_geocoder_to_coordinates(query):\n",
    "    \"\"\"\n",
    "    Extracts location names from query, geocodes them, returns latitude and longitude values.\n",
    "\n",
    "    USE THIS TOOL WHEN:\n",
    "    - A specific location name is mentioned in the query and geospatial coordinates are required\n",
    "\n",
    "    DO NOT USE THIS TOOL WHEN:\n",
    "    - Nonspecific location names like 'cafe' or 'park' are named in the query\n",
    "    \"\"\"\n",
    "    print(f\"üìç GEOCODER: Processing query: '{query}'\")\n",
    "\n",
    "    geolocator = Nominatim(user_agent=\"react_agent_geocoder\")\n",
    "\n",
    "    if AI_PLATFORM == \"ANTHROPIC\":\n",
    "        llm = ChatAnthropic(temperature=0, model_name=\"claude-3-7-sonnet-20250219\")\n",
    "    elif AI_PLATFORM == \"OPENAI\":\n",
    "        llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "    elif AI_PLATFORM == \"WATSONX\":\n",
    "        llm = ChatWatsonx(temperature=0, model_name=\"ibm/granite-34b-code-instruct\")\n",
    "\n",
    "    print(\"üìç GEOCODER: Initialized LLM\")\n",
    "\n",
    "    # Extract location entities using LLM\n",
    "    location_extraction_prompt = f\"\"\"\n",
    "    Extract all location names from the following query. \n",
    "    Include cities, addresses, landmarks, neighborhoods, regions, or any other geographic references.\n",
    "    Return ONLY the location names separated by semicolons.\n",
    "    If no locations are found, return \"NO_LOCATION\".\n",
    "    \n",
    "    Query: {query}\n",
    "    \n",
    "    Location names:\n",
    "    \"\"\"\n",
    "\n",
    "    location_extraction = llm.invoke(location_extraction_prompt).content\n",
    "\n",
    "    # Process extracted locations\n",
    "    possible_locations = (\n",
    "        [loc.strip() for loc in location_extraction.split(\";\")]\n",
    "        if location_extraction and location_extraction != \"NO_LOCATION\"\n",
    "        else [query]\n",
    "    )\n",
    "    print(f\"üìç GEOCODER: Extracted locations: {possible_locations}\")\n",
    "\n",
    "    # Process locations\n",
    "    results = []\n",
    "    for location in possible_locations:\n",
    "        try:\n",
    "            geocode_result = geolocator.geocode(\n",
    "                location, exactly_one=True, language=\"en\", timeout=None\n",
    "            )\n",
    "\n",
    "            if geocode_result:\n",
    "                print(\n",
    "                    f\"üìç GEOCODER: Found {location} at {geocode_result.latitude}, {geocode_result.longitude}\"\n",
    "                )\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"query_text\": location,\n",
    "                        \"geocoded\": {\n",
    "                            \"name\": geocode_result.address,\n",
    "                            \"lat\": geocode_result.latitude,\n",
    "                            \"lon\": geocode_result.longitude,\n",
    "                        },\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"üìç GEOCODER: Error with {location}: {str(e)} ‚ùå\")\n",
    "            continue\n",
    "\n",
    "    # Try suggestion if no results found\n",
    "    if not results:\n",
    "        suggestion_prompt = \"\"\"\n",
    "        I could not geocode any locations from the query: \"{query}\"\n",
    "        Suggest a better location reference or return \"NO_SUGGESTION\".\n",
    "        \"\"\"\n",
    "\n",
    "        suggestion = llm.invoke(suggestion_prompt.format(query=query)).content\n",
    "\n",
    "        if suggestion and suggestion != \"NO_SUGGESTION\":\n",
    "            try:\n",
    "                geocode_result = geolocator.geocode(\n",
    "                    suggestion, exactly_one=True, language=\"en\", timeout=None\n",
    "                )\n",
    "                if geocode_result:\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"query_text\": suggestion,\n",
    "                            \"geocoded\": {\n",
    "                                \"name\": geocode_result.address,\n",
    "                                \"lat\": geocode_result.latitude,\n",
    "                                \"lon\": geocode_result.longitude,\n",
    "                            },\n",
    "                        }\n",
    "                    )\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # Return error if no results found\n",
    "    if not results:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": \"Could not geocode any locations from the query\",\n",
    "            \"query\": query,\n",
    "        }\n",
    "\n",
    "    # Narrow it down further\n",
    "    primary_result = results[0]\n",
    "    if len(results) > 1:\n",
    "        location_names = [r[\"geocoded\"][\"name\"] for r in results]\n",
    "\n",
    "        primary_prompt = \"\"\"\n",
    "        Which ONE location is the primary focus of this query: \"{query}\"\n",
    "        Locations: {locations}\n",
    "        Return ONLY the name of the primary location.\n",
    "        \"\"\"\n",
    "\n",
    "        primary_name = llm.invoke(\n",
    "            primary_prompt.format(query=query, locations=\", \".join(location_names))\n",
    "        ).content\n",
    "\n",
    "        # Find closest match\n",
    "        for result in results:\n",
    "            if primary_name.lower() in result[\"geocoded\"][\"name\"].lower():\n",
    "                primary_result = result\n",
    "                break\n",
    "\n",
    "    print(\n",
    "        f\"üìç GEOCODER: Identified primary location: {primary_result['geocoded']['name']} ‚úÖ\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"success\": True,\n",
    "        \"locations\": results,\n",
    "        \"primary_location\": primary_result[\"geocoded\"],\n",
    "        \"query\": query,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def text_to_coordinates_to_folium_map(query):\n",
    "    \"\"\"\n",
    "    Visualize coordinates extracted from a query on a Folium map in a Jupyter notebook.\n",
    "\n",
    "    This tool is always delivered as the end result of a visualization query.\n",
    "\n",
    "    USE THIS TOOL WHEN:\n",
    "    - The query mentions visualization or mapping and the result from the previous tool returns a list of coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üåé VISUALIZATION: Starting to process query: '{query}'\")\n",
    "\n",
    "    if AI_PLATFORM == \"ANTHROPIC\":\n",
    "        llm = ChatAnthropic(temperature=0, model_name=\"claude-3-7-sonnet-20250219\")\n",
    "    elif AI_PLATFORM == \"OPENAI\":\n",
    "        llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "    elif AI_PLATFORM == \"WATSONX\":\n",
    "        llm = ChatWatsonx(temperature=0, model_name=\"ibm/granite-34b-code-instruct\")\n",
    "        \n",
    "    print(\"üåé VISUALIZATION: Initialized LLM\")\n",
    "\n",
    "    # Extract coordinates using LLM\n",
    "    extraction_prompt = f\"\"\"\n",
    "    Extract all geographic coordinates from the following text.\n",
    "    Return ONLY a JSON array of objects with 'lat' and 'lon' properties.\n",
    "    If a location name is mentioned instead of coordinates, do not include it.\n",
    "    Only include explicitly mentioned coordinates.\n",
    "    \n",
    "    Example valid response:\n",
    "    [\n",
    "      {{\"lat\": 40.7411, \"lon\": -73.9897, \"name\": \"Madison Square Park\"}},\n",
    "      {{\"lat\": 40.7128, \"lon\": -74.0060}}\n",
    "    ]\n",
    "    \n",
    "    If you can identify names for the points, include them as a \"name\" property.\n",
    "    If no coordinates are found, return an empty array: []\n",
    "    \n",
    "    Text: {query}\n",
    "    \n",
    "    JSON array:\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"üåé VISUALIZATION: Sending coordinate extraction prompt to LLM\")\n",
    "\n",
    "    # Get coordinates from LLM\n",
    "    extraction_result = llm.invoke(extraction_prompt).content\n",
    "    print(\"üåé VISUALIZATION: Received extraction result from LLM\")\n",
    "\n",
    "    # Clean up the response to ensure it's valid JSON\n",
    "    # Sometimes the LLM adds text before or after the JSON array\n",
    "    json_match = re.search(r\"\\[\\s*\\{.*\\}\\s*\\]\", extraction_result, re.DOTALL)\n",
    "    if json_match:\n",
    "        clean_json = json_match.group(0)\n",
    "    else:\n",
    "        clean_json = extraction_result\n",
    "\n",
    "    # Parse the JSON response\n",
    "    try:\n",
    "        coordinates_list = json.loads(clean_json)\n",
    "        print(\"üåé VISUALIZATION: Successfully parsed JSON response\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"üåé VISUALIZATION: Error parsing JSON response: {str(e)}\")\n",
    "        error_msg = \"Failed to extract coordinates from the query. Please provide coordinates in a clear format. ‚ùå\"\n",
    "        print(f\"üåé VISUALIZATION: Error - {error_msg}\")\n",
    "        return error_msg\n",
    "\n",
    "    # Validate extracted coordinates\n",
    "    if not coordinates_list:\n",
    "        error_msg = \"\"\"\n",
    "        No coordinates found in the query. \n",
    "        Please provide coordinates in formats like '40.7411, -73.9897' or 'latitude 40.7411 longitude -73.9897'.\n",
    "        \"\"\"\n",
    "        print(f\"üåé VISUALIZATION: Error - {error_msg} ‚ùå\")\n",
    "        return error_msg\n",
    "\n",
    "    print(f\"üåé VISUALIZATION: Extracted {len(coordinates_list)} coordinate pairs from query\")\n",
    "\n",
    "    print(\"üåé VISUALIZATION: Creating Folium map\")\n",
    "    folium_map = folium.Map(tiles=\"Cartodb dark_matter\")\n",
    "\n",
    "    for point in coordinates_list:\n",
    "        popup_text = point.get(\"name\", f\"Lat: {point['lat']}, Lon: {point['lon']}\")\n",
    "        folium.Marker(\n",
    "            location=[point[\"lat\"], point[\"lon\"]], popup=popup_text, tooltip=popup_text\n",
    "        ).add_to(folium_map)\n",
    "\n",
    "    # Adjust map bounding box \n",
    "    if coordinates_list:\n",
    "        lats = [point[\"lat\"] for point in coordinates_list]\n",
    "        lons = [point[\"lon\"] for point in coordinates_list]\n",
    "        folium_map.fit_bounds(\n",
    "            [[min(lats), min(lons)], [max(lats), max(lons)]]\n",
    "        )\n",
    "\n",
    "    print(f\"üåé VISUALIZATION: Successfully created map with {len(coordinates_list)} points ‚úÖ\")\n",
    "    \n",
    "    # Display map immediately in Jupyter Notebook\n",
    "    display(folium_map)\n",
    "\n",
    "    return f\"Map with {len(coordinates_list)} points created and displayed.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all four tools have been prepared, we can now load them into the agentic app, which will share the results between tools to more effectively answer queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_street_network(query, display_result=True):\n",
    "    \"\"\"\n",
    "    Process street network queries using a ReACT agent with AQL, OSMnx, Geocoding, and Visualization tools.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize LLM\n",
    "    if AI_PLATFORM == \"ANTHROPIC\":\n",
    "        llm = ChatAnthropic(temperature=0, model_name=\"claude-3-7-sonnet-20250219\")\n",
    "    elif AI_PLATFORM == \"OPENAI\":\n",
    "        llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "    elif AI_PLATFORM == \"WATSONX\":\n",
    "        llm = ChatWatsonx(temperature=0, model_name=\"ibm/granite-34b-code-instruct\")\n",
    "\n",
    "    # Cache the results stored by each tool so it can be passed to the next tool\n",
    "    # Schema: { <tool_name>: <tool_result> }\n",
    "    tool_results = {}\n",
    "\n",
    "    def add_memory(tool):\n",
    "        \"\"\"\n",
    "        Equip each tool with the ability to call itself AND include the results of the preceding tool\n",
    "        The output is a new LangChain tool where the called function is the wrapped original tool\n",
    "\n",
    "        This allows the ReACT agent to call the wrapped tool, which generates the intermediate query based\n",
    "        on the cached result, then invokes the tool with the enhanced query\n",
    "\n",
    "        This should enable the output of the agent to better handle hybrid queries reliant on multiple tools\n",
    "        \"\"\"\n",
    "\n",
    "        def tool_with_memory(inter_query):\n",
    "            # As the ReACT agent passes intermediate queries between tools,\n",
    "            # we want to check for the string USE_PREVIOUS_RESULT<tool_name> in the query,\n",
    "            # If the string is present, then we swap in the results from the previous tool\n",
    "            # to assemble the full enhanced intermediate query\n",
    "\n",
    "            for tool_name, result in tool_results.items():\n",
    "                placeholder = f\"USE_PREVIOUS_RESULT<{tool_name}>\"\n",
    "                if placeholder in inter_query:\n",
    "                    inter_query = inter_query.replace(placeholder, str(result))\n",
    "\n",
    "            # Execute the tool with the enhanced intermediate query\n",
    "            result = tool.invoke(inter_query)\n",
    "            tool_results[tool.name] = result\n",
    "            return result\n",
    "\n",
    "        # Create a new tool with the memory-enabled function\n",
    "        return Tool(\n",
    "            name=tool.name,\n",
    "            description=tool.description\n",
    "            + \"\\nYou can refer to results from other tools using USE_PREVIOUS_RESULT<tool_name>.\",\n",
    "            func=tool_with_memory,\n",
    "        )\n",
    "\n",
    "    tools = [\n",
    "        text_to_aql_to_text,\n",
    "        text_to_osmnx_algorithm_to_text,\n",
    "        text_to_geocoder_to_coordinates,\n",
    "        text_to_coordinates_to_folium_map,\n",
    "    ]\n",
    "\n",
    "    # Wrap all tools\n",
    "    memory_tools = [add_memory(tool) for tool in tools]\n",
    "\n",
    "    # Create the Agentic App\n",
    "    app = create_react_agent(llm, memory_tools)\n",
    "\n",
    "    # Create system message to explain tool result references\n",
    "    # Note from the tool_with_memory function above that the USE_PREVIOUS_RESULT string will be replaced\n",
    "    # by the results of the preceding tool, before being passed to the next tool\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"\n",
    "    You have access to multiple tools and can use the results of previous tool calls in new ones.\n",
    "    To use a previous result, include USE_PREVIOUS_RESULT<tool_name> in your action input.\n",
    "    For example: \n",
    "    Action: text_to_osmnx_algorithm_to_text\n",
    "    Action Input: Analyze the graph from USE_PREVIOUS_RESULT<text_to_aql_to_text> using PageRank algorithm.\"\"\"\n",
    "    )\n",
    "\n",
    "    # Run the agent\n",
    "    final_state = app.invoke(\n",
    "        {\"messages\": [system_message, HumanMessage(content=query)]}\n",
    "    )\n",
    "    response = final_state[\"messages\"][-1].content\n",
    "\n",
    "    # Display the result if specified, if not then return it for potential further processing\n",
    "    if display_result:\n",
    "        display(Markdown(f\"{response}\"))\n",
    "        return None\n",
    "    else:\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Querying the Agentic App to Retrieve Insights into an Urban Street Network\n",
    "Now that the data and tools have been created, let's run a series of natural language queries to generate useful information about the area around One Madison Avenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_street_network(\"Which intersection in the street network is the best place to set up my new corner store, and what's the closest bank?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_street_network(\"Visualize the top three most difficult to reach healthcare facilities in the street network.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_street_network(\"What is the nearest bike shelter to One Madison Avenue, and how many meters does it take to walk there via a pathway?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_street_network(\"How far are all of the public transport locations from each other? Compare the straight line with their walking distance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_street_network(\"What are all the food places near the National Museum of Mathematics? Which one is easiest to get to by walking, and how long?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_street_network(\"Visualize the top five most crowded intersections in the street network and tell me their coordinates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_street_network(\"Starting from the Flatiron Building, how long is the path to the Museum of Mathematics, through Madison Square Park, and back?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_street_network(\"In minutes, which is faster by bike from 23rd St Station - Met Life Insurance Tower, Gramercy Tavern, or Chelsea Piers Fitness?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Querying the Agentic App to Retrieve Insights into a Rural Street Network and Health Facility Data\n",
    "Let's build a new graph in my father's village of Gomnati in Nilphamari District of Bangladesh, to analyze an area with significantly different geography from New York City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the map of Gomnati village using Gomnati Primary School as the center point\n",
    "# We overwrite the in-memory OSMnx graph as the tools refer to this variable name specifically\n",
    "G_ox = ox.graph_from_point((26.195655, 88.852847), dist=3500.00)\n",
    "\n",
    "for node1, node2, edge_dict in G_ox.edges(data=True):\n",
    "    edge_dict.pop('geometry', None)\n",
    "\n",
    "ox.plot_graph(G_ox)\n",
    "print(f\"Graph of street network within a 3300 meter radius of Gomnati Primary School: {G_ox}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the nodes in the OSMnx graph do not include the address, we geocode each node\n",
    "geolocator = Nominatim(user_agent=\"osmnx_geocoder\")\n",
    "for node_id, node_data in G_ox.nodes(data=True):\n",
    "    lat = node_data['y']\n",
    "    lon = node_data['x']\n",
    "    \n",
    "    try:\n",
    "        # Use reverse geocoding on points to get address information\n",
    "        location = geolocator.reverse(f\"{lat}, {lon}\", exactly_one=True, timeout=None)\n",
    "        if location:\n",
    "            # Add address information to the node\n",
    "            G_ox.nodes[node_id]['address'] = location.address\n",
    "\n",
    "        # Avoid possible rate limiting by waiting a bit between each node\n",
    "        time.sleep(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding node {node_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_id, node_data in G_ox.nodes(data=True):\n",
    "    G_ox.nodes[node_id]['ID'] = node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gomnati_filepath = \"./data/gomnati.graphml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox.io.save_graphml(G_ox, gomnati_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ox = ox.io.load_graphml(gomnati_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list_with_addresses = list(G_ox.nodes(data=True))\n",
    "print(f\"Sample node data with address: {node_list_with_addresses[0]}\")\n",
    "print(f\"Sample node data with address: {node_list_with_addresses[65]}\")\n",
    "print(f\"Sample node data with address: {node_list_with_addresses[82]}\")\n",
    "print(f\"Sample node data with address: {node_list_with_addresses[34]}\")\n",
    "\n",
    "edge_list = list(G_ox.edges(data=True))\n",
    "print(f\"Sample edge data: {edge_list [0]}\")\n",
    "print(f\"Sample edge data: {edge_list [65]}\")\n",
    "print(f\"Sample edge data: {edge_list [120]}\")\n",
    "print(f\"Sample edge data: {edge_list [34]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {'building': True, 'amenity': True, 'healthcare': True, 'office': True, 'public_transport': True, 'craft': True, 'historic': True}\n",
    "features_gdf = ox.features.features_from_point((26.200, 88.850), tags, dist=3500.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utm_crs = ox.projection.project_gdf(features_gdf).crs\n",
    "features_gdf['lat'] = features_gdf.to_crs(utm_crs).centroid.to_crs(features_gdf.crs).y\n",
    "features_gdf['lon'] = features_gdf.to_crs(utm_crs).centroid.to_crs(features_gdf.crs).x\n",
    "features_gdf_adjusted = features_gdf.drop(columns=['geometry'])\n",
    "\n",
    "features_json_str = features_gdf_adjusted.reset_index().to_json(orient='records')\n",
    "features_records = json.loads(features_json_str)\n",
    "\n",
    "for feature in features_records:\n",
    "    for key, value in list(feature.items()):\n",
    "        if value is None:\n",
    "            del feature[key]\n",
    "\n",
    "print(f\"Sample feature data: {features_records[0]}\\n\")\n",
    "print(f\"Sample feature data: {features_records[1]}\\n\")\n",
    "print(f\"Sample feature data: {features_records[2]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To augment the potential of our insights, let's pull in some critical data. https://healthsites.io/ was created by the Global Healthsites Mapping Project, with the aim of making global health facility data open and accessible. They have per-country datasets that can be retrieved via their API or downloadable as geospatial files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded the Bangladesh healthsites data as a Shapefile from healthsites.io\n",
    "# Load this into a GeoDataFrame to access Point data\n",
    "bd_healthsites_df = gpd.read_file('data/Bangladesh-node.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no Polygon shapes in this dataset, just points, so not need to use centroids\n",
    "bd_healthsites_df['lon'] = bd_healthsites_df.geometry.apply(lambda p: p.x)\n",
    "bd_healthsites_df['lat'] = bd_healthsites_df.geometry.apply(lambda p: p.y)\n",
    "\n",
    "# Drop the geometry, duplicate, and empty columns that prevent serialization\n",
    "bd_healthsites_df_adjusted = bd_healthsites_df.drop(columns=['geometry','is_in_heal','changeset_'])\n",
    "bd_healthsites_json_str = bd_healthsites_df_adjusted.reset_index().to_json(orient='records')\n",
    "bd_healthsites_records = json.loads(bd_healthsites_json_str)\n",
    "\n",
    "print(f\"Sample healthsite data: {bd_healthsites_records[0]}\\n\")\n",
    "print(f\"Sample healthsite data: {bd_healthsites_records[1]}\\n\")\n",
    "print(f\"Sample healthsite data: {bd_healthsites_records[2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database to store graph and features collection for Gomnati\n",
    "if not sys_db.has_database('gomnati'):\n",
    "    sys_db.create_database('gomnati')\n",
    "\n",
    "gomnati_db = client.db('gomnati',username=adb_user,password=adb_pass,verify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ox_adb = nxadb.MultiDiGraph(\n",
    "    name=\"G_ox_adb\",\n",
    "    db=gomnati_db,\n",
    "    incoming_graph_data=G_ox,\n",
    "    overwrite_graph=True\n",
    ")\n",
    "print(f\"Graph of Gomnati, Bangladesh rural network persisted to ArangoDB: {G_ox_adb}\")\n",
    "\n",
    "print(f\"True number of nodes in G_ox_adb is: {G_ox_adb.number_of_nodes()}\")\n",
    "print(f\"True number of edges in G_ox_adb is: {G_ox_adb.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gomnati_db.has_collection('features'):\n",
    "    gomnati_db.delete_collection('features')\n",
    "features_collection = gomnati_db.create_collection('features')\n",
    "\n",
    "features_collection.insert_many(features_records)\n",
    "print(f\"Added {len(features_records)} feature records to ArangoDB 'features' collection in the Gomnati database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gomnati_db.has_collection('healthsites'):\n",
    "    gomnati_db.delete_collection('healthsites')\n",
    "healthsites_collection = gomnati_db.create_collection('healthsites')\n",
    "\n",
    "healthsites_collection.insert_many(bd_healthsites_records)\n",
    "print(f\"Added {len(bd_healthsites_records)} feature records to ArangoDB 'features' collection in the Gomnati database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ArangoGraph for the Gomnati database\n",
    "arango_graph = ArangoGraph(gomnati_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_street_network(\"What is the shortest path to the nearest health facility to ‡¶ó‡ßã‡¶Æ‡¶®‡¶æ‡¶§‡¶ø ‡¶Æ‡¶π‡¶æ‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶æ‡¶≤‡ßü?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_street_network(\"Visualize the three most isolated addresses in this street network.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
